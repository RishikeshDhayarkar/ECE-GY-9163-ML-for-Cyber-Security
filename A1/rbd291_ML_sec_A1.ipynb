{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rbd291_ML_sec_A1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Esvtk-IjY5ke",
        "mcpIJZAI8HCE",
        "QgWlX-IC-RAP",
        "xfvhtIi4-WlS",
        "VHbmT0IY1dbE",
        "63Hu5fSW730S",
        "tQWEV-XpjGVM",
        "C_XnQ-A3OuXV"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Esvtk-IjY5ke"
      },
      "source": [
        "#<h1> IG calculation </h1>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktNuZv5k1456",
        "outputId": "a1773119-27f8-42f1-ba98-014ea841bb10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK6wt5jX16aJ"
      },
      "source": [
        "FOLDERNAME = 'lemm_stop/part1'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/{}'.format(FOLDERNAME))"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIltC4UEaN8t"
      },
      "source": [
        "Generating Spam email count and ham email count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Anuzo8Gr3O3p",
        "outputId": "355f5cb7-0c57-4f96-a7c8-7ecbd5ed96be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "dir_list = ['/content/drive/My Drive/lemm_stop/part1', '/content/drive/My Drive/lemm_stop/part2', '/content/drive/My Drive/lemm_stop/part3', '/content/drive/My Drive/lemm_stop/part4',\\\n",
        "            '/content/drive/My Drive/lemm_stop/part5', '/content/drive/My Drive/lemm_stop/part6', '/content/drive/My Drive/lemm_stop/part7', '/content/drive/My Drive/lemm_stop/part8',\\\n",
        "            '/content/drive/My Drive/lemm_stop/part9']         \n",
        "\n",
        "spam_count = 0\n",
        "ham_count = 0\n",
        "import os\n",
        "for directory_in_str in dir_list:\n",
        "    directory = os.fsencode(directory_in_str)\n",
        "    for file in os.listdir(directory):\n",
        "        filename = os.fsdecode(file)\n",
        "        if filename.endswith(\".txt\"):\n",
        "            if 'sp' in filename:\n",
        "                spam_count+=1\n",
        "            else:\n",
        "                ham_count+=1               \n",
        "        else:\n",
        "            continue\n",
        "print(spam_count, ham_count)            "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "432 2170\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eBaW5saZCFb"
      },
      "source": [
        "def remove_values_from_list(the_list, val):\n",
        "   return [value for value in the_list if value != val]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXLmD-nX0wbX",
        "outputId": "38c82373-547a-4221-b148-27bc25321865",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import os\n",
        "import re\n",
        "import string\n",
        "from pathlib import Path\n",
        "import nltk\n",
        "nltk.download('words')\n",
        "wd = set(nltk.corpus.words.words())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMaf5uD53lzi"
      },
      "source": [
        "<h2>Processing train data</h2>\n",
        "Processing includes converting all characters to lower case, removing numbers, removing all punctuations, removing new line and tab spaces, stripping spaces at the beginning and at the end if the email, removing the word 'subject'. \n",
        "After this is done all the email is grouped into either spam or legit categories. The same process is applied on the test set as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhlQVN5T4tM1",
        "outputId": "93503dc4-49ca-473b-dca5-6c66ad83259b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "dir_list = ['/content/drive/My Drive/lemm_stop/part1/', '/content/drive/My Drive/lemm_stop/part2/', '/content/drive/My Drive/lemm_stop/part3/', '/content/drive/My Drive/lemm_stop/part4/',\\\n",
        "            '/content/drive/My Drive/lemm_stop/part5/', '/content/drive/My Drive/lemm_stop/part6/', '/content/drive/My Drive/lemm_stop/part7/', '/content/drive/My Drive/lemm_stop/part8/',\\\n",
        "            '/content/drive/My Drive/lemm_stop/part9/']   \n",
        "\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "from pathlib import Path\n",
        "import nltk\n",
        "nltk.download('words')\n",
        "wd = set(nltk.corpus.words.words())\n",
        "cts = 0\n",
        "wordsets = []\n",
        "spam_docs = []\n",
        "legit_docs = []\n",
        "\n",
        "processed_spam_docs = []\n",
        "processed_legit_docs = []\n",
        "\n",
        "for directory_in_str in dir_list:\n",
        "    directory = os.fsencode(directory_in_str)\n",
        "    for file in os.listdir(directory):\n",
        "        filename = os.fsdecode(file)\n",
        "        if filename.endswith(\".txt\"):\n",
        "            data = Path(directory_in_str + filename).read_text()\n",
        "            data = data.lower()\n",
        "            data = re.sub(r'\\d+', '', data)\n",
        "            data = data.translate(str.maketrans('','', string.punctuation))\n",
        "            data = data.replace('\\n','')\n",
        "            data = data.replace('\\t','')\n",
        "            data = data.strip()\n",
        "            data = [w for w in data.split() if len(w)>1]\n",
        "            data.remove('subject')\n",
        "            data = ' '.join(remove_values_from_list(data, 'np'))\n",
        "            result = []\n",
        "            for w in nltk.wordpunct_tokenize(data):\n",
        "                if w.lower() in wd:\n",
        "                    result.append(w)\n",
        "            result = ' '.join(result)\n",
        "\n",
        "            if 'sp' in filename:\n",
        "                processed_spam_docs.append(result.split(' '))\n",
        "                spam_docs.append(frozenset(result.split(' ')))\n",
        "            else:\n",
        "                processed_legit_docs.append(result.split(' '))\n",
        "                legit_docs.append(frozenset(result.split(' ')))\n",
        "        else:\n",
        "            continue\n",
        "          "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iO3hDB5E3v2R"
      },
      "source": [
        "<h2>Processing test data</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QBiPap23p7f",
        "outputId": "71fd16af-dc5e-4204-f1bc-c3c7429ebff5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "dir_list = ['/content/drive/My Drive/lemm_stop/part9/']   \n",
        "\n",
        "import os\n",
        "import re\n",
        "import string\n",
        "from pathlib import Path\n",
        "import nltk\n",
        "nltk.download('words')\n",
        "wd = set(nltk.corpus.words.words())\n",
        "\n",
        "spam_docs_test = []\n",
        "legit_docs_test = []\n",
        "processed_spam_docs_test = []\n",
        "processed_legit_docs_test = []\n",
        "\n",
        "for directory_in_str in dir_list:\n",
        "    directory = os.fsencode(directory_in_str)\n",
        "    for file in os.listdir(directory):\n",
        "        filename = os.fsdecode(file)\n",
        "        if filename.endswith(\".txt\"):\n",
        "            data = Path(directory_in_str + filename).read_text()\n",
        "            data = data.lower()\n",
        "            data = re.sub(r'\\d+', '', data)\n",
        "            data = data.translate(str.maketrans('','', string.punctuation))\n",
        "            data = data.replace('\\n','')\n",
        "            data = data.replace('\\t','')\n",
        "            data = data.strip()\n",
        "            data = [w for w in data.split() if len(w)>1]\n",
        "            data.remove('subject')\n",
        "            data = ' '.join(remove_values_from_list(data, 'np'))\n",
        "            result = []\n",
        "            for w in nltk.wordpunct_tokenize(data):\n",
        "                if w.lower() in wd:\n",
        "                    result.append(w)\n",
        "            result = ' '.join(result)\n",
        "\n",
        "            if 'sp' in filename:\n",
        "                processed_spam_docs_test.append(result.split(' '))\n",
        "                spam_docs_test.append(frozenset(result.split(' ')))\n",
        "            else:\n",
        "                processed_legit_docs_test.append(result.split(' '))\n",
        "                legit_docs_test.append(frozenset(result.split(' ')))\n",
        "        else:\n",
        "            continue\n",
        "          "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN8NQZ5jahl9"
      },
      "source": [
        "spam_docs_counts = []\n",
        "legit_docs_counts = []\n",
        "for word in wd:\n",
        "    count = sum( 1 for s in spam_docs if word in s )\n",
        "    if count>0:\n",
        "        spam_docs_counts.append((word, count))  \n",
        "\n",
        "for word in wd:\n",
        "    count = sum( 1 for s in legit_docs if word in s )\n",
        "    if count>0:\n",
        "        legit_docs_counts.append((word, count))       "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eumd4ZsBXuHX"
      },
      "source": [
        "spam_docs_counts_d = {}\n",
        "legit_docs_counts_d = {}\n",
        "\n",
        "spam_docs_counts_d = dict(spam_docs_counts)\n",
        "legit_docs_counts_d = dict(legit_docs_counts)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDg0GA_6bAl4"
      },
      "source": [
        "all_words = set()\n",
        "\n",
        "for key in spam_docs_counts_d.keys():\n",
        "    all_words.add(key)\n",
        "\n",
        "for key in legit_docs_counts_d.keys():\n",
        "    all_words.add(key)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GtKM6HWaap3"
      },
      "source": [
        "H(C) value for the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NT5rN6ZXBegZ",
        "outputId": "d32a6259-6395-4f8a-d704-1eddc3baf78b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "p = (spam_count+1)/(spam_count + ham_count +2)\n",
        "H_of_C = -p*np.log(p) - (1-p)*np.log(1-p) \n",
        "print(H_of_C)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4499426139156912\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-v9x5__-D0j"
      },
      "source": [
        "IG calculation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLhn9Aiy7OGZ"
      },
      "source": [
        "IG_dict = {}\n",
        "\n",
        "for word in all_words:\n",
        "\n",
        "    try:\n",
        "        if spam_docs_counts_d[word]:\n",
        "            sp_word = spam_docs_counts_d[word] + 1\n",
        "    except KeyError:\n",
        "        sp_word = 1   \n",
        "\n",
        "    try:\n",
        "        if legit_docs_counts_d[word]:\n",
        "            lg_word = legit_docs_counts_d[word] + 1\n",
        "    except KeyError:\n",
        "        lg_word = 1   \n",
        "\n",
        "    H_C_given_X = (-1)*(((sp_word/(spam_count + ham_count + 2)) * np.log(sp_word/(sp_word + lg_word)))\\\n",
        "                   + ((lg_word/(spam_count + ham_count + 2)) * np.log(lg_word/(sp_word + lg_word)))\\\n",
        "                   + (((spam_count - sp_word)/(spam_count + ham_count + 2)) * np.log((spam_count - sp_word)/(spam_count + ham_count - sp_word - lg_word)))\\\n",
        "                   + (((ham_count - lg_word)/(spam_count + ham_count + 2)) * np.log((ham_count - lg_word)/(spam_count + ham_count - sp_word - lg_word))))\n",
        "\n",
        "\n",
        "    IG_dict[word] = H_of_C - H_C_given_X\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHqNEDgMak4y"
      },
      "source": [
        "Sorting all IG values in descending order"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HBgD7WiGAVz"
      },
      "source": [
        "IG_dict_sorted = {k: v for k, v in sorted(IG_dict.items(), key=lambda item: item[1], reverse=True)}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDlJLZcbart5"
      },
      "source": [
        "Extracting the top 10, 100 and 1000 words based on sorted IG and printing the top 10 words along with their IG value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXNmDtGbGWz-",
        "outputId": "1bac1b4d-8efb-4258-cf8e-d5fbbaa4fae2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "top_10_IG = []\n",
        "top_100_IG = []\n",
        "top_1000_IG = []\n",
        "\n",
        "top_10_IG_words = []\n",
        "top_100_IG_words = []\n",
        "top_1000_IG_words = []\n",
        "\n",
        "i = 0\n",
        "print(\"List of Top 10 words:\")\n",
        "for key in IG_dict_sorted.keys():\n",
        "    if i>=10:\n",
        "        break\n",
        "    top_10_IG.append((key, IG_dict_sorted[key])) \n",
        "    top_10_IG_words.append(key) \n",
        "    print(key, IG_dict_sorted[key])\n",
        "    i+=1 \n",
        "\n",
        "i = 0\n",
        "for key in IG_dict_sorted.keys():\n",
        "    if i>=100:\n",
        "        break\n",
        "    top_100_IG.append((key, IG_dict_sorted[key]))\n",
        "    top_100_IG_words.append(key)   \n",
        "    i+=1   \n",
        "\n",
        "i = 0\n",
        "for key in IG_dict_sorted.keys():\n",
        "    if i>=1000:\n",
        "        break\n",
        "    top_1000_IG.append((key, IG_dict_sorted[key])) \n",
        "    top_1000_IG_words.append(key)  \n",
        "    i+=1       "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "List of Top 10 words:\n",
            "language 0.1400199328310175\n",
            "remove 0.11776741926774453\n",
            "free 0.11516525688714896\n",
            "linguistic 0.10152229995769935\n",
            "university 0.09970059497459127\n",
            "money 0.08321112933282104\n",
            "click 0.07076502226173614\n",
            "market 0.06503070551026874\n",
            "our 0.0628574754117483\n",
            "business 0.06117324098477023\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Y4M9ex-ZFfp"
      },
      "source": [
        "<h1>Create feature vectors for all documents</h1>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-aNsbu19-Jo"
      },
      "source": [
        "Generating binary feature vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIfbx4VVirNe"
      },
      "source": [
        "def gen_ft_nb(N, spam_or_ham):\n",
        "    train_data = []\n",
        "    for doc in spam_or_ham:\n",
        "        feature_vector = [0]*N\n",
        "        if N==10:\n",
        "            wl = top_10_IG_words\n",
        "        elif N==100:\n",
        "            wl = top_100_IG_words\n",
        "        elif N==1000:\n",
        "            wl = top_1000_IG_words\n",
        "\n",
        "        for w in wl:\n",
        "            if w in doc:\n",
        "                feature_vector[wl.index(w)] = 1\n",
        "        train_data.append(feature_vector)\n",
        "    return train_data    \n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTOpIB5GbWAP"
      },
      "source": [
        "Generating feature vectors for train_data of sizes 10, 100 and 1000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPdDhhdwi0Wc"
      },
      "source": [
        "train_data_10_nb = gen_ft_nb(10, processed_legit_docs) + gen_ft_nb(10, processed_spam_docs)\n",
        "\n",
        "train_data_100_nb = gen_ft_nb(100, processed_legit_docs) + gen_ft_nb(100, processed_spam_docs)\n",
        "\n",
        "train_data_1000_nb = gen_ft_nb(1000, processed_legit_docs) + gen_ft_nb(1000, processed_spam_docs)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm6VeLTbbdRI"
      },
      "source": [
        "Generating feature vectors for test_data of sizes 10, 100 and 1000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2-slhme_Ql8"
      },
      "source": [
        "test_data_10_nb = gen_ft_nb(10, processed_legit_docs_test) + gen_ft_nb(10, processed_spam_docs_test)\n",
        "\n",
        "test_data_100_nb = gen_ft_nb(100, processed_legit_docs_test) + gen_ft_nb(100, processed_spam_docs_test)\n",
        "\n",
        "test_data_1000_nb = gen_ft_nb(1000, processed_legit_docs_test) + gen_ft_nb(1000, processed_spam_docs_test)\n",
        "\n",
        "true_labels_test = [0] * 241 + [1] * 48"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcpIJZAI8HCE"
      },
      "source": [
        "#<h2>Binomial NB classifier</h2>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-acCwlEypOhQ"
      },
      "source": [
        "P_of_spam = (spam_count+1)/(spam_count + ham_count+2)\n",
        "P_of_legit = (ham_count+1)/(spam_count + ham_count+2)\n",
        "\n",
        "def binomial_NB(data, wl):\n",
        "    P_of_x_given_spam = 1\n",
        "    P_of_x_given_legit = 1\n",
        "    for i, w in enumerate(wl):\n",
        "        try:\n",
        "            if spam_docs_counts_d[w]:\n",
        "                sp_word = spam_docs_counts_d[w] + 1           \n",
        "\n",
        "        except KeyError:\n",
        "            sp_word = 1    \n",
        "\n",
        "        try:\n",
        "            if legit_docs_counts_d[w]:\n",
        "                lg_word = legit_docs_counts_d[w] + 1\n",
        "\n",
        "        except KeyError:\n",
        "            lg_word = 1       \n",
        "\n",
        "        Pis = sp_word/(spam_count+2)\n",
        "        Pih = lg_word/(ham_count+2)\n",
        "\n",
        "        P_of_x_given_spam = P_of_x_given_spam * (np.power(Pis, data[i]) * np.power((1 - Pis),(1 - data[i])))\n",
        "        P_of_x_given_legit = P_of_x_given_legit * (np.power(Pih, data[i]) * np.power((1 - Pih),(1 - data[i])))\n",
        "\n",
        "    P_of_x = (P_of_spam * P_of_x_given_spam) + (P_of_legit * P_of_x_given_legit)\n",
        "\n",
        "    P_of_spam_given_x = (P_of_x_given_spam * P_of_spam) / P_of_x\n",
        "\n",
        "    P_of_legit_given_x = (P_of_x_given_legit * P_of_legit) / P_of_x\n",
        "\n",
        "\n",
        "    if P_of_spam_given_x > P_of_legit_given_x:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0   \n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2425bT9F9WX"
      },
      "source": [
        "Prediction on test data with N = 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w-ybVGPoPuQ",
        "outputId": "02015598-1a89-4477-c56f-6f4352fe9e00",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "pred_labels = []\n",
        "for fv in test_data_10_nb:\n",
        "    pred_labels.append(binomial_NB(fv, top_10_IG_words))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(true_labels_test, pred_labels)\n",
        "print(cm)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[238   3]\n",
            " [ 10  38]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeoWFydsSjwK"
      },
      "source": [
        "def print_spam_precision_recall(cm):\n",
        "    Spam_precision = (cm[1][1]/(cm[1][1]+cm[1][0]))\n",
        "    Spam_recall = (cm[1][1]/(cm[1][1]+cm[0][1]))\n",
        "    Accuracy = (cm[0][0]+cm[1][1])/(289)\n",
        "\n",
        "    print(f'Spam_precision = {Spam_precision*100}')\n",
        "    print(f'Spam_recall = {Spam_recall*100}')\n",
        "    # print(f'Accuracy = {Accuracy*100}')\n",
        "    return"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FapbNmh3v4x",
        "outputId": "a9c62d38-0b27-4616-c1fa-de9fb73bcf45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print_spam_precision_recall(cm)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spam_precision = 79.16666666666666\n",
            "Spam_recall = 92.6829268292683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hs2uQ3TnGFgD"
      },
      "source": [
        "\n",
        "Prediction on test data with N = 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZQoLbSo2Zs9",
        "outputId": "3d626644-d01d-4c42-9478-dfcf54619f37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "pred_labels = []\n",
        "for fv in test_data_100_nb:\n",
        "    pred_labels.append(binomial_NB(fv, top_100_IG_words))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(true_labels_test, pred_labels)\n",
        "print(cm)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[240   1]\n",
            " [ 13  35]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXiFJ3eC5qIX",
        "outputId": "f3c6f506-38e7-4539-9dd4-1c7eb43f6024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print_spam_precision_recall(cm)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spam_precision = 72.91666666666666\n",
            "Spam_recall = 97.22222222222221\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydA0_N_XGHIS"
      },
      "source": [
        "\n",
        "Prediction on test data with N = 1000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u77JGojaC_l-",
        "outputId": "9c6a3c34-da24-4799-b7fb-9db3a63ae70e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "pred_labels = []\n",
        "for fv in test_data_1000_nb:\n",
        "    pred_labels.append(binomial_NB(fv, top_1000_IG_words))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(true_labels_test, pred_labels)\n",
        "print(cm)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in double_scalars\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:32: RuntimeWarning: invalid value encountered in double_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[241   0]\n",
            " [ 14  34]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Yph5z3eOFip",
        "outputId": "0e11b8b8-1496-44b3-bd81-6332b2ffada3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print_spam_precision_recall(cm)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spam_precision = 70.83333333333334\n",
            "Spam_recall = 100.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QgWlX-IC-RAP"
      },
      "source": [
        "#<h2>Multinomial NB with binary features</h2>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-yIsoV7uGOay"
      },
      "source": [
        "Generating term frequencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEk3ICtXyu_A"
      },
      "source": [
        "import collections\n",
        "TF_spam = {}\n",
        "TF_legit = {}\n",
        "\n",
        "TF_legit = collections.Counter(all_words)\n",
        "TF_spam = collections.Counter(all_words)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksV2DXCjT1sl"
      },
      "source": [
        "for doc in processed_legit_docs:\n",
        "    for word in doc:\n",
        "        TF_legit[word]+=1\n",
        "\n",
        "for doc in processed_spam_docs:\n",
        "    for word in doc:\n",
        "        TF_spam[word]+=1"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6Hp1X547_th"
      },
      "source": [
        "Generating term frequency feature vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06yADsyVk_GN"
      },
      "source": [
        "import collections\n",
        "def gen_ft_mnb(N, spam_or_ham):\n",
        "    train_data = []\n",
        "    for doc in spam_or_ham:\n",
        "        doc_dict = collections.Counter(doc)\n",
        "        feature_vector = [0]*N\n",
        "        if N==10:\n",
        "            wl = top_10_IG_words\n",
        "        elif N==100:\n",
        "            wl = top_100_IG_words\n",
        "        elif N==1000:\n",
        "            wl = top_1000_IG_words\n",
        "\n",
        "        for w in wl:\n",
        "            if w in doc_dict:\n",
        "                feature_vector[wl.index(w)] = doc_dict[w]\n",
        "        train_data.append(feature_vector)\n",
        "    return train_data   "
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxRNNwktdHVz"
      },
      "source": [
        "Generating feature vectors of size 10, 100 and 1000 with term frequencies for the train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6e_x6z_qoNbP"
      },
      "source": [
        "train_data_10_mnb = gen_ft_mnb(10, processed_legit_docs) + gen_ft_mnb(10, processed_spam_docs)\n",
        "\n",
        "train_data_100_mnb = gen_ft_mnb(100, processed_legit_docs) + gen_ft_mnb(100, processed_spam_docs)\n",
        "\n",
        "train_data_1000_mnb = gen_ft_mnb(1000, processed_legit_docs) + gen_ft_mnb(1000, processed_spam_docs)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIWoFQRQ-ctl"
      },
      "source": [
        "P_of_spam = (spam_count + 1) / (spam_count + ham_count + 2)\n",
        "P_of_legit = (ham_count + 1) / (spam_count + ham_count + 2)\n",
        "\n",
        "def multinomial_NB(data, wl):\n",
        "    P_of_x_given_spam = 1\n",
        "    P_of_x_given_legit = 1\n",
        "\n",
        "    M = len(wl)\n",
        "\n",
        "    TF_legit_sum = 0\n",
        "    TF_spam_sum = 0\n",
        "\n",
        "    for word in wl:\n",
        "        TF_legit_sum += TF_legit[word]\n",
        "        TF_spam_sum += TF_spam[word]\n",
        "\n",
        "    for i, w in enumerate(wl):\n",
        "\n",
        "        Pis = TF_spam[w]/(TF_spam_sum + M)\n",
        "        Pih = TF_legit[w]/(TF_legit_sum + M)\n",
        "        \n",
        "        P_of_x_given_spam = P_of_x_given_spam * (np.power(Pis, data[i]))\n",
        "        P_of_x_given_legit = P_of_x_given_legit * (np.power(Pih, data[i]))\n",
        "\n",
        "    P_of_spam_given_x = (P_of_x_given_spam * P_of_spam)\n",
        "    P_of_legit_given_x = (P_of_x_given_legit * P_of_legit)\n",
        "\n",
        "\n",
        "    if P_of_spam_given_x / P_of_legit_given_x > 1:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0   \n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwCHM_IvdVkv"
      },
      "source": [
        "Classification on test set for N=10 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2nSxuKIhSJ7t",
        "outputId": "db02fecf-ff20-4b04-ca85-5ba3321c7539",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "pred_labels = []\n",
        "for fv in test_data_10_nb:\n",
        "    pred_labels.append(multinomial_NB(fv, top_10_IG_words))\n",
        "\n",
        "true_labels_test = [0] * 241 + [1] * 48\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(true_labels_test, pred_labels)\n",
        "print(cm)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[236   5]\n",
            " [  9  39]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bi6KHh6cGttB",
        "outputId": "4eddbf7e-4ca7-4a2c-ece9-ae68bfec9144",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print_spam_precision_recall(cm)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spam_precision = 81.25\n",
            "Spam_recall = 88.63636363636364\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wXQ05Azdj6f"
      },
      "source": [
        "Classification on test set for N=100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIQSYOQMESRj",
        "outputId": "9e02eb19-4b6c-42df-849d-378d62a758f4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "pred_labels = []\n",
        "for fv in test_data_100_nb:\n",
        "    pred_labels.append(multinomial_NB(fv, top_100_IG_words))\n",
        "\n",
        "true_labels_test = [0] * 241 + [1] * 48\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(true_labels_test, pred_labels)\n",
        "print(cm)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[239   2]\n",
            " [  0  48]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwZ2LubjHXjb",
        "outputId": "43435f6b-2c0f-4e79-d768-bb776c62dd6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print_spam_precision_recall(cm)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spam_precision = 100.0\n",
            "Spam_recall = 96.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNpcngT5dqRE"
      },
      "source": [
        "Classification on test set for N=1000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX33bTNAEVzR",
        "outputId": "a05d7b89-437b-40ff-ee0d-9fe062b82c2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "pred_labels = []\n",
        "for fv in test_data_1000_nb:\n",
        "    pred_labels.append(multinomial_NB(fv, top_1000_IG_words))\n",
        "\n",
        "true_labels_test = [0] * 241 + [1] * 48\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(true_labels_test, pred_labels)\n",
        "print(cm)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in double_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[239   2]\n",
            " [ 12  36]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGMFKDtuPTON",
        "outputId": "0e0cc005-a550-45aa-8c0e-75ccd372d412",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print_spam_precision_recall(cm)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spam_precision = 75.0\n",
            "Spam_recall = 94.73684210526315\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xfvhtIi4-WlS"
      },
      "source": [
        "#<h2>Multinomial NB with TF features</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWNUX2zePFOD"
      },
      "source": [
        "P_of_spam = (spam_count+1)/(spam_count + ham_count+2)\n",
        "P_of_legit = (ham_count+1)/(spam_count + ham_count+2)\n",
        "\n",
        "def multinomial_NB_TF(data, wl):\n",
        "    P_of_x_given_spam = 1\n",
        "    P_of_x_given_legit = 1\n",
        "\n",
        "    M = len(wl)\n",
        "\n",
        "    TF_legit_sum = 0\n",
        "    TF_spam_sum = 0\n",
        "\n",
        "    for word in wl:\n",
        "        TF_legit_sum += TF_legit[word]\n",
        "        TF_spam_sum += TF_spam[word]\n",
        "\n",
        "    for i, w in enumerate(wl):\n",
        "\n",
        "        Pis = TF_spam[w]/(TF_spam_sum + M)\n",
        "        Pih = TF_legit[w]/(TF_legit_sum + M)\n",
        "\n",
        "        P_of_x_given_spam = P_of_x_given_spam * (np.power(Pis, data[i]))\n",
        "        P_of_x_given_legit = P_of_x_given_legit * (np.power(Pih, data[i]))\n",
        "\n",
        "    P_of_spam_given_x = (P_of_x_given_spam * P_of_spam)\n",
        "\n",
        "    P_of_legit_given_x = (P_of_x_given_legit * P_of_legit)\n",
        "\n",
        "\n",
        "    if P_of_spam_given_x / P_of_legit_given_x > 1:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0   \n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GOv6lbOdyS-"
      },
      "source": [
        "Generating feature vectors of size 10, 100 and 1000 with term frequencies on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gED4Za8gR1iw"
      },
      "source": [
        "test_data_10_mnb = gen_ft_mnb(10, processed_legit_docs_test) + gen_ft_mnb(10, processed_spam_docs_test)\n",
        "\n",
        "test_data_100_mnb = gen_ft_mnb(100, processed_legit_docs_test) + gen_ft_mnb(100, processed_spam_docs_test)\n",
        "\n",
        "test_data_1000_mnb = gen_ft_mnb(1000, processed_legit_docs_test) + gen_ft_mnb(1000, processed_spam_docs_test)\n",
        "\n",
        "true_labels_test = [0] * 241 + [1] * 48"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iv0_B_kLd8i4"
      },
      "source": [
        "Classification on test set with N=10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zjyHTSJPE8D",
        "outputId": "9bc823ef-effd-47ea-f2e9-ac9af037b7ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "pred_labels = []\n",
        "for fv in test_data_10_mnb:\n",
        "    pred_labels.append(multinomial_NB_TF(fv, top_10_IG_words))\n",
        "\n",
        "true_labels_test = [0] * 241 + [1] * 48\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(true_labels_test, pred_labels)\n",
        "print(cm)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[236   5]\n",
            " [ 10  38]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GER3W2i9T25k",
        "outputId": "b2323f4b-e9a7-413b-84cb-ac22688b273a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print_spam_precision_recall(cm)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spam_precision = 79.16666666666666\n",
            "Spam_recall = 88.37209302325581\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tx0jX3DGeCLw"
      },
      "source": [
        "Classification on test set with N=100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qT5Kf4-kSOL_",
        "outputId": "03e54bcf-9851-427b-c4c8-d22271699553",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "pred_labels = []\n",
        "for fv in test_data_100_mnb:\n",
        "    pred_labels.append(multinomial_NB_TF(fv, top_100_IG_words))\n",
        "\n",
        "true_labels_test = [0] * 241 + [1] * 48\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(true_labels_test, pred_labels)\n",
        "print(cm)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[237   4]\n",
            " [  8  40]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in double_scalars\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hi_HlYiUCMm",
        "outputId": "7b9c0fb9-8260-4296-badf-66eca701bf48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print_spam_precision_recall(cm)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spam_precision = 83.33333333333334\n",
            "Spam_recall = 90.9090909090909\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOilrbPueEZo"
      },
      "source": [
        "Classification on test set with N=1000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYCDT6e8SN_3",
        "outputId": "73ef267a-0013-41a6-aa24-57c58320650f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "pred_labels = []\n",
        "for fv in test_data_1000_mnb:\n",
        "    pred_labels.append(multinomial_NB_TF(fv, top_1000_IG_words))\n",
        "\n",
        "true_labels_test = [0] * 241 + [1] * 48\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(true_labels_test, pred_labels)\n",
        "print(cm)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: RuntimeWarning: invalid value encountered in double_scalars\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:30: RuntimeWarning: divide by zero encountered in double_scalars\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[240   1]\n",
            " [ 24  24]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9VbK0kDUJft",
        "outputId": "633955ad-951e-4188-dae3-10b68c6f4edf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "print_spam_precision_recall(cm)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Spam_precision = 50.0\n",
            "Spam_recall = 96.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VHbmT0IY1dbE"
      },
      "source": [
        "#<h2>SVM with binary features</h2>\n",
        "SVM was performed using both TF features and binary features seperately. The classifiers trained on binary features worked better. \n",
        "Parameters of SVM -  C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XVZj0tuY1fZg"
      },
      "source": [
        "train_data_10_nb_np = np.array(train_data_10_nb)\n",
        "train_data_100_nb_np = np.array(train_data_100_nb)\n",
        "train_data_1000_nb_np = np.array(train_data_1000_nb)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Glgr_eh10Fe"
      },
      "source": [
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fsp9TiBScQ-m"
      },
      "source": [
        "true_labels = [0] * 2170 + [1] * 432"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0g7f9Ihh58Iw"
      },
      "source": [
        "SVM on feature vector of length 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pr7GTuXc2ezt",
        "outputId": "34e2cf57-dcb5-4984-beed-e2d364aa66d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "clf.fit(train_data_10_nb_np, true_labels)\n",
        "\n",
        "test_data_10_nb = gen_ft_nb(10, processed_legit_docs_test) + gen_ft_nb(10, processed_spam_docs_test)\n",
        "test_data_10_nb_np = np.array(test_data_10_nb)\n",
        "test_pred = clf.predict(test_data_10_nb_np)\n",
        "\n",
        "true_labels_test = [0] * 241 + [1] * 48\n",
        "cm_test = confusion_matrix(true_labels_test, test_pred)\n",
        "print(cm_test)\n",
        "print_spam_precision_recall(cm_test)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[238   3]\n",
            " [  4  44]]\n",
            "Spam_precision = 91.66666666666666\n",
            "Spam_recall = 93.61702127659575\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViB5_13W6GXL"
      },
      "source": [
        "SVM on feature vector of length 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_oPCadZ5ssQ",
        "outputId": "53507edd-32e0-465e-d58c-2068742307a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "clf.fit(train_data_100_nb_np, true_labels)\n",
        "\n",
        "test_data_100_nb = gen_ft_nb(100, processed_legit_docs_test) + gen_ft_nb(100, processed_spam_docs_test)\n",
        "test_data_100_nb_np = np.array(test_data_100_nb)\n",
        "test_pred = clf.predict(test_data_100_nb_np)\n",
        "true_labels_test = [0] * 241 + [1] * 48\n",
        "cm_test = confusion_matrix(true_labels_test, test_pred)\n",
        "print(cm_test)\n",
        "print_spam_precision_recall(cm_test)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[241   0]\n",
            " [  2  46]]\n",
            "Spam_precision = 95.83333333333334\n",
            "Spam_recall = 100.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kr2mEzXp6Hhx"
      },
      "source": [
        "SVM on feature vector of length 1000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq04nkQj530L",
        "outputId": "007eb3ed-e2bb-4dca-e6d0-1e57c2f2d97c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "clf.fit(train_data_1000_nb_np, true_labels)\n",
        "\n",
        "test_data_1000_nb = gen_ft_nb(1000, processed_legit_docs_test) + gen_ft_nb(1000, processed_spam_docs_test)\n",
        "test_data_1000_nb_np = np.array(test_data_1000_nb)\n",
        "test_pred = clf.predict(test_data_1000_nb_np)\n",
        "true_labels_test = [0] * 241 + [1] * 48\n",
        "cm_test = confusion_matrix(true_labels_test, test_pred)\n",
        "print(cm_test)\n",
        "print_spam_precision_recall(cm_test)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[241   0]\n",
            " [  0  48]]\n",
            "Spam_precision = 100.0\n",
            "Spam_recall = 100.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63Hu5fSW730S"
      },
      "source": [
        "#<h2>SVM with term frequency features</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtT_DKTE53xX"
      },
      "source": [
        "train_data_10_mnb_np = np.array(train_data_10_mnb)\n",
        "train_data_100_mnb_np = np.array(train_data_100_mnb)\n",
        "train_data_1000_mnb_np = np.array(train_data_1000_mnb)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFAY4owu9ldi"
      },
      "source": [
        "SVM on feature vector of length 10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a84neTec8X8k",
        "outputId": "ec30bbce-ca8e-4f45-dc38-1b652abdd2f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "clf.fit(train_data_10_mnb_np, true_labels)\n",
        "\n",
        "test_data_10_mnb = gen_ft_mnb(10, processed_legit_docs_test) + gen_ft_mnb(10, processed_spam_docs_test)\n",
        "test_data_10_mnb_np = np.array(test_data_10_mnb)\n",
        "test_pred = clf.predict(test_data_10_mnb_np)\n",
        "\n",
        "true_labels_test = [0] * 241 + [1] * 48\n",
        "cm_test = confusion_matrix(true_labels_test, test_pred)\n",
        "print(cm_test)\n",
        "print_spam_precision_recall(cm_test)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[238   3]\n",
            " [ 12  36]]\n",
            "Spam_precision = 75.0\n",
            "Spam_recall = 92.3076923076923\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX4KhKkQ9mpo"
      },
      "source": [
        "SVM on feature vector of length 100\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5hjMryg8_qn",
        "outputId": "3f0244d0-1691-42be-9015-fb044da01a45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "clf.fit(train_data_100_mnb_np, true_labels)\n",
        "\n",
        "test_data_100_mnb = gen_ft_mnb(100, processed_legit_docs_test) + gen_ft_mnb(100, processed_spam_docs_test)\n",
        "test_data_100_mnb_np = np.array(test_data_100_mnb)\n",
        "test_pred = clf.predict(test_data_100_mnb_np)\n",
        "\n",
        "true_labels_test = [0] * 241 + [1] * 48\n",
        "cm_test = confusion_matrix(true_labels_test, test_pred)\n",
        "print(cm_test)\n",
        "print_spam_precision_recall(cm_test)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[241   0]\n",
            " [ 12  36]]\n",
            "Spam_precision = 75.0\n",
            "Spam_recall = 100.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtXmb5289pmp"
      },
      "source": [
        "SVM on feature vector of length 1000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbcf-r4X9UR6",
        "outputId": "ef47cadd-e09e-40a6-d27b-98c63ddc780d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        }
      },
      "source": [
        "clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
        "clf.fit(train_data_1000_mnb_np, true_labels)\n",
        "\n",
        "test_data_1000_mnb = gen_ft_mnb(1000, processed_legit_docs_test) + gen_ft_mnb(1000, processed_spam_docs_test)\n",
        "test_data_1000_mnb_np = np.array(test_data_1000_mnb)\n",
        "test_pred = clf.predict(test_data_1000_mnb_np)\n",
        "\n",
        "true_labels_test = [0] * 241 + [1] * 48\n",
        "cm_test = confusion_matrix(true_labels_test, test_pred)\n",
        "print(cm_test)\n",
        "print_spam_precision_recall(cm_test)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[241   0]\n",
            " [  9  39]]\n",
            "Spam_precision = 81.25\n",
            "Spam_recall = 100.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQWEV-XpjGVM"
      },
      "source": [
        "# Adversarial setting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itxdwat4X4qU"
      },
      "source": [
        "This is an alternate approach for creating a classifier in an adversarial setting. This is a modification of whats is presented in the paper. I was not able to implement the exact techniques presented in the paper. So, I came up with an intuitive and simple approach to solve this problem. \n",
        "\n",
        "In this approch I iterate over the feature vector of every email. If a 0 is found it is converted to 1 and this modified feature vector is fed to the Bernoulli NB classifier. The classifier returns P(spam/x) and P(ham/x), store these values with their respective index at which the change was performed. Once this calculated revert the changes made at that index. This is repeated for all the indices of the feature vector. Now sort all probabilities in increasing order of P(spam/x). Since we are interested in generating emails that result in low values of P(spam/x), it makes sense to make changes in the order presented in this sorted list. \n",
        "\n",
        "For every email in the test set make change a 0 to a 1 at the index presented in the sorted list. After every change calculate P(spam/x) and P(ham/x). If P(spam/x) > P(ham/x) then break out of the loop i.e no more chnages are necessary for this email. If this condition does not hold true then continue making more changes at the selected indices. Keep a track of the cost for every change that is made. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQArdE2CiM5r"
      },
      "source": [
        "P_of_spam = (spam_count+1)/(spam_count + ham_count+2)\n",
        "P_of_legit = (ham_count+1)/(spam_count + ham_count+2)\n",
        "\n",
        "def binomial_NB_prob(data, wl):\n",
        "    P_of_x_given_spam = 1\n",
        "    P_of_x_given_legit = 1\n",
        "    for i, w in enumerate(wl):\n",
        "        try:\n",
        "            if spam_docs_counts_d[w]:\n",
        "                sp_word = spam_docs_counts_d[w] + 1           \n",
        "\n",
        "        except KeyError:\n",
        "            sp_word = 1    \n",
        "\n",
        "        try:\n",
        "            if legit_docs_counts_d[w]:\n",
        "                lg_word = legit_docs_counts_d[w] + 1\n",
        "\n",
        "        except KeyError:\n",
        "            lg_word = 1       \n",
        "\n",
        "        Pis = sp_word/(spam_count+2)\n",
        "        Pih = lg_word/(ham_count+2)\n",
        "\n",
        "        P_of_x_given_spam = P_of_x_given_spam * (np.power(Pis, data[i]) * np.power((1 - Pis),(1 - data[i])))\n",
        "        P_of_x_given_legit = P_of_x_given_legit * (np.power(Pih, data[i]) * np.power((1 - Pih),(1 - data[i])))\n",
        "\n",
        "    P_of_x = (P_of_spam * P_of_x_given_spam) + (P_of_legit * P_of_x_given_legit)\n",
        "    P_of_spam_given_x = (P_of_x_given_spam * P_of_spam) / P_of_x\n",
        "    P_of_legit_given_x = (P_of_x_given_legit * P_of_legit) / P_of_x\n",
        "\n",
        "\n",
        "    return (P_of_spam_given_x, P_of_legit_given_x)  "
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qysHBGeZtThp"
      },
      "source": [
        "test_data_10_nb = gen_ft_nb(10, processed_legit_docs_test) + gen_ft_nb(10, processed_spam_docs_test)"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjsrgPLijFTs"
      },
      "source": [
        "import copy \n",
        "original_probs = []\n",
        "for te in test_data_10_nb:\n",
        "    original_probs.append(binomial_NB_prob(te, top_10_IG_words))"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MD4GfWDwmhWL"
      },
      "source": [
        "modified_test_set = copy.deepcopy(test_data_10_nb)"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga1Wk6pplb-y"
      },
      "source": [
        "new_probs_full = []\n",
        "true_labels_test = [0] * 241 + [1] * 48\n",
        "\n",
        "for roll, te in enumerate(test_data_10_nb):\n",
        "    if true_labels_test[roll] == 1:\n",
        "        new_prob_list = []\n",
        "        for ind, val in enumerate(te):\n",
        "            if val==0:\n",
        "                modified_test_set[roll][ind] = 1\n",
        "                P_of_spam_given_x, P_of_legit_given_x = binomial_NB_prob(modified_test_set[roll], top_10_IG_words)\n",
        "                new_prob_list.append((P_of_spam_given_x, P_of_legit_given_x, ind))\n",
        "                modified_test_set[roll][ind] = 0\n",
        "\n",
        "            else:\n",
        "                P_of_spam_given_x, P_of_legit_given_x = binomial_NB_prob(modified_test_set[roll], top_10_IG_words)\n",
        "                new_prob_list.append((P_of_spam_given_x, P_of_legit_given_x, ind))\n",
        "\n",
        "        new_probs_full.append(new_prob_list)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAsgY4ic3hfP"
      },
      "source": [
        "# sort probabilities\n",
        "sorted_probs = []\n",
        "for prob_tup_list in new_probs_full:\n",
        "    sorted_probs.append(sorted(prob_tup_list, key=lambda tup: tup[0]))"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T4RRzobb7_t3"
      },
      "source": [
        "mod_test_fin = copy.deepcopy(test_data_10_nb[-48:])"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bETdx22OoVdV"
      },
      "source": [
        "cost_per_email = []\n",
        "\n",
        "for roll, te in enumerate(test_data_10_nb[-48:]):\n",
        "    cost = 0\n",
        "    if true_labels_test[-48:][roll] == 1:\n",
        "        for ind, tup_list in enumerate(sorted_probs):\n",
        "            for tup in tup_list:\n",
        "                p1, p2, k = tup\n",
        "                mod_test_fin[roll][k] = 1\n",
        "                cost+=1\n",
        "                P_of_spam_given_x, P_of_legit_given_x = binomial_NB_prob(mod_test_fin[roll], top_10_IG_words)\n",
        "\n",
        "                if P_of_spam_given_x < P_of_legit_given_x:\n",
        "                    flag = 1\n",
        "                    break\n",
        "                else:\n",
        "                    continue\n",
        "            if flag == 1:\n",
        "                break\n",
        "            else:\n",
        "                continue                    \n",
        "        if cost>3:\n",
        "            mod_test_fin[roll] = test_data_10_nb[-48:][roll]\n",
        "            cost = 0\n",
        "            cost_per_email.append(cost)\n",
        "        else:\n",
        "            cost_per_email.append(cost)     "
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41jq6hkBCelB",
        "outputId": "82eb0797-7dd0-451a-f384-66670d639318",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fin_test = test_data_10_nb[:241] + mod_test_fin\n",
        "len(fin_test)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "289"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vol-z8RTZdW"
      },
      "source": [
        "Performing classification on the emails modified by the adversary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KttKM9j_7PU6",
        "outputId": "e819d11c-57f6-4b44-a373-5ebbba10fb07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "pred_labels = []\n",
        "for fv in fin_test:\n",
        "    pred_labels.append(binomial_NB(fv, top_10_IG_words))\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(true_labels_test, pred_labels)\n",
        "print(cm)\n",
        "print_spam_precision_recall(cm)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[238   3]\n",
            " [ 42   6]]\n",
            "Spam_precision = 12.5\n",
            "Spam_recall = 66.66666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkeXLJq9cWe0"
      },
      "source": [
        "Printing all cost values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x46vPQOBXJ8O",
        "outputId": "96ef8e2e-468a-4a49-c530-76b7a7fb64c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 823
        }
      },
      "source": [
        "cost_per_email"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 0,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 3,\n",
              " 3,\n",
              " 3,\n",
              " 1,\n",
              " 0,\n",
              " 1,\n",
              " 0,\n",
              " 3,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 1,\n",
              " 2,\n",
              " 2,\n",
              " 1,\n",
              " 1,\n",
              " 3,\n",
              " 1,\n",
              " 3,\n",
              " 3,\n",
              " 2,\n",
              " 2,\n",
              " 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z7MLFVHecS8S"
      },
      "source": [
        "Minimum cost value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J1F-x-OVmoB",
        "outputId": "5904530b-fc58-441b-a61e-b8b857a630d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "minimum_adversary_cost = sum(cost_per_email)/48\n",
        "print(minimum_adversary_cost)"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.5833333333333333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i54Nz-JpLRaP"
      },
      "source": [
        "Modified Classifier part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sNt_S9gxIajx"
      },
      "source": [
        "train_data_10_nb = gen_ft_nb(10, processed_legit_docs) + gen_ft_nb(10, processed_spam_docs)\n",
        "modified_train_set = copy.deepcopy(train_data_10_nb)\n",
        "true_labels = [0] * 2170 + [1] * 432"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6x2wRAE5L298"
      },
      "source": [
        "new_probs_full = []\n",
        "\n",
        "for roll, te in enumerate(train_data_10_nb):\n",
        "    if true_labels[roll] == 1:\n",
        "        new_prob_list = []\n",
        "        for ind, val in enumerate(te):\n",
        "            if val==0:\n",
        "                modified_train_set[roll][ind] = 1\n",
        "                P_of_spam_given_x, P_of_legit_given_x = binomial_NB_prob(modified_train_set[roll], top_10_IG_words)\n",
        "                new_prob_list.append((P_of_spam_given_x, P_of_legit_given_x, ind))\n",
        "                modified_train_set[roll][ind] = 0\n",
        "\n",
        "            else:\n",
        "                P_of_spam_given_x, P_of_legit_given_x = binomial_NB_prob(modified_train_set[roll], top_10_IG_words)\n",
        "                new_prob_list.append((P_of_spam_given_x, P_of_legit_given_x, ind))\n",
        "\n",
        "        new_probs_full.append(new_prob_list)\n"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6oh7UVhMcX0"
      },
      "source": [
        "# sort probabilities\n",
        "sorted_probs = []\n",
        "for prob_tup_list in new_probs_full:\n",
        "    sorted_probs.append(sorted(prob_tup_list, key=lambda tup: tup[0]))"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTj-z8uZM00u"
      },
      "source": [
        "mod_train_fin = copy.deepcopy(train_data_10_nb[-432:])\n",
        "train_orginal_probs = original_probs[-432:]"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rtq4KFsNEbN"
      },
      "source": [
        "cost_per_email = []\n",
        "\n",
        "for roll, te in enumerate(train_data_10_nb[-432:]):\n",
        "    cost = 0\n",
        "    if true_labels[-432:][roll] == 1:\n",
        "        for ind, tup_list in enumerate(sorted_probs):\n",
        "            for tup in tup_list:\n",
        "                p1, p2, k = tup\n",
        "                mod_train_fin[roll][k] = 1\n",
        "                cost+=1\n",
        "                P_of_spam_given_x, P_of_legit_given_x = binomial_NB_prob(mod_train_fin[roll], top_10_IG_words)\n",
        "\n",
        "                if P_of_spam_given_x < P_of_legit_given_x:\n",
        "                    flag = 1\n",
        "                    break\n",
        "                else:\n",
        "                    continue\n",
        "            if flag == 1:\n",
        "                break\n",
        "            else:\n",
        "                continue            \n",
        "        cost_per_email.append(cost)\n",
        "        if cost==10:\n",
        "            mod_train_fin[roll] = train_data_10_nb[-432:][roll]  "
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOw5zwrhNoYr",
        "outputId": "b62dd164-2846-4a60-bafa-4825116208a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "fin_train = train_data_10_nb[:2170] + mod_train_fin\n",
        "len(fin_train)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2602"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CepqzBJTMg7"
      },
      "source": [
        "Modified classifier applied on the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr57IrgiOGlb",
        "outputId": "b69aab4c-2daa-407d-df15-4eaadbacec0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "fin_train_np = np.array(fin_train)\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "clf = BernoulliNB()\n",
        "clf.fit(fin_train_np, true_labels)\n",
        "\n",
        "test_data_10_nb = gen_ft_nb(10, processed_legit_docs_test) + gen_ft_nb(10, processed_spam_docs_test)\n",
        "test_data_10_nb_np = np.array(test_data_10_nb)\n",
        "test_pred = clf.predict(test_data_10_nb_np)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "true_labels_test = [0] * 241 + [1] * 48\n",
        "cm_test = confusion_matrix(true_labels_test, test_pred)\n",
        "print(cm_test)\n",
        "print_spam_precision_recall(cm_test)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[239   2]\n",
            " [ 15  33]]\n",
            "Spam_precision = 68.75\n",
            "Spam_recall = 94.28571428571428\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uq6qsPDGOx8D"
      },
      "source": [
        ""
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_XnQ-A3OuXV"
      },
      "source": [
        "#(EXTRA) Adversarial setting \n",
        "This is an attempt to implement the exact technique that is presented in the paper. This approch did not give expected results hence I above modified approch was implemented instead of this. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BX-6-UafUc33"
      },
      "source": [
        "P_of_spam = (spam_count+1)/(spam_count + ham_count+2)\n",
        "P_of_legit = (ham_count+1)/(spam_count + ham_count+2)\n",
        "\n",
        "def binomial_NB_prob(data, wl):\n",
        "    P_of_x_given_spam = 1\n",
        "    P_of_x_given_legit = 1\n",
        "    for i, w in enumerate(wl):\n",
        "        try:\n",
        "            if spam_docs_counts_d[w]:\n",
        "                sp_word = spam_docs_counts_d[w] + 1           \n",
        "\n",
        "        except KeyError:\n",
        "            sp_word = 1    \n",
        "\n",
        "        try:\n",
        "            if legit_docs_counts_d[w]:\n",
        "                lg_word = legit_docs_counts_d[w] + 1\n",
        "\n",
        "        except KeyError:\n",
        "            lg_word = 1       \n",
        "\n",
        "        Pis = sp_word/(spam_count+2)\n",
        "        Pih = lg_word/(ham_count+2)\n",
        "\n",
        "        P_of_x_given_spam = P_of_x_given_spam * (np.power(Pis, data[i]) * np.power((1 - Pis),(1 - data[i])))\n",
        "        P_of_x_given_legit = P_of_x_given_legit * (np.power(Pih, data[i]) * np.power((1 - Pih),(1 - data[i])))\n",
        "\n",
        "    P_of_x = (P_of_spam * P_of_x_given_spam) + (P_of_legit * P_of_x_given_legit)\n",
        "    P_of_spam_given_x = (P_of_x_given_spam * P_of_spam) / P_of_x\n",
        "    P_of_legit_given_x = (P_of_x_given_legit * P_of_legit) / P_of_x\n",
        "\n",
        "\n",
        "    return (P_of_spam_given_x, P_of_legit_given_x)  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-sKZx60mTqD"
      },
      "source": [
        "def binomial_NB_prob_prod(data, wl):\n",
        "    P_of_x_given_spam_prod = []\n",
        "    P_of_x_given_legit_prod = []\n",
        "\n",
        "    P_of_x_given_spam = 1\n",
        "    P_of_x_given_legit = 1\n",
        "    for i, w in enumerate(wl):\n",
        "        try:\n",
        "            if spam_docs_counts_d[w]:\n",
        "                sp_word = spam_docs_counts_d[w] + 1           \n",
        "\n",
        "        except KeyError:\n",
        "            sp_word = 1    \n",
        "\n",
        "        try:\n",
        "            if legit_docs_counts_d[w]:\n",
        "                lg_word = legit_docs_counts_d[w] + 1\n",
        "\n",
        "        except KeyError:\n",
        "            lg_word = 1       \n",
        "\n",
        "        Pis = sp_word/(spam_count+2)\n",
        "        Pih = lg_word/(ham_count+2)\n",
        "\n",
        "        P_of_x_given_spam = P_of_x_given_spam * (np.power(Pis, data[i]) * np.power((1 - Pis),(1 - data[i])))\n",
        "        P_of_x_given_spam_prod.append((np.power(Pis, data[i]) * np.power((1 - Pis),(1 - data[i]))))\n",
        "\n",
        "        P_of_x_given_legit = P_of_x_given_legit * (np.power(Pih, data[i]) * np.power((1 - Pih),(1 - data[i])))\n",
        "        P_of_x_given_legit_prod.append((np.power(Pih, data[i]) * np.power((1 - Pih),(1 - data[i]))))\n",
        "\n",
        "    P_of_x = (P_of_spam * P_of_x_given_spam) + (P_of_legit * P_of_x_given_legit)\n",
        "\n",
        "    P_of_spam_given_x = (P_of_x_given_spam * P_of_spam) / P_of_x\n",
        "\n",
        "    P_of_legit_given_x = (P_of_x_given_legit * P_of_legit) / P_of_x\n",
        "\n",
        "\n",
        "    return (P_of_x_given_spam_prod, P_of_x_given_legit_prod)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wOkCSMJHPKHs"
      },
      "source": [
        "def FindMCC(i, w, x, WL):\n",
        "    if w<=0:\n",
        "        return (0,[])\n",
        "\n",
        "    if i==0:\n",
        "        return (float('inf'), [])\n",
        "\n",
        "    min_cost = float('inf')\n",
        "    min_list = []\n",
        "\n",
        "    for xi_prime in [1,0]:\n",
        "\n",
        "        P_of_x_given_spam_prod, P_of_x_given_legit_prod = binomial_NB_prob_prod(x, WL)\n",
        "        x_mod = x.copy()\n",
        "        xi = x[i]\n",
        "        x_mod[i] = xi_prime\n",
        "\n",
        "        Mod_P_of_x_given_spam_prod, Mod_P_of_x_given_legit_prod = binomial_NB_prob_prod(x_mod, WL)\n",
        "\n",
        "        LO_c_of_xi = np.log(P_of_x_given_spam_prod[i] / P_of_x_given_legit_prod[i])\n",
        "        LO_c_of_xi_prime =  np.log(Mod_P_of_x_given_spam_prod[i] / Mod_P_of_x_given_legit_prod[i])\n",
        "\n",
        "        if xi == xi_prime:\n",
        "            delta_LO_i_xi_prime = 0\n",
        "            Wi_of_xi_xi_prime = 0\n",
        "        else:\n",
        "            delta_LO_i_xi_prime = LO_c_of_xi - LO_c_of_xi_prime\n",
        "            Wi_of_xi_xi_prime = 1\n",
        "\n",
        "        if delta_LO_i_xi_prime >= 0:\n",
        "            cur_cost, cur_list = FindMCC(i-1, w - delta_LO_i_xi_prime, x, WL)\n",
        "            cur_cost = cur_cost + Wi_of_xi_xi_prime \n",
        "            cur_list.append((i, xi_prime))\n",
        "\n",
        "            if cur_cost < min_cost:\n",
        "                min_cost = cur_cost\n",
        "                min_list = cur_list\n",
        "\n",
        "    return (min_cost, min_list)                "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjBCg4b2Otk7"
      },
      "source": [
        "def A(x, word_list):\n",
        "\n",
        "    Uc_pp = 1\n",
        "    Uc_pn = -10\n",
        "    Uc_np = -1\n",
        "    Uc_nn = 1\n",
        "\n",
        "    Ua_pp = 0\n",
        "    Ua_pn = 0\n",
        "    Ua_np = 20\n",
        "    Ua_nn = 0\n",
        "\n",
        "    P_of_spam_given_x, P_of_legit_given_x, P_of_x_given_spam, P_of_x_given_legit = binomial_NB_prob(x, word_list)\n",
        "\n",
        "    LO_c_of_x = np.log(P_of_spam_given_x / P_of_legit_given_x)\n",
        "\n",
        "    LT_of_Uc = np.log((Uc_nn - Uc_pn) / (Uc_pp - Uc_np))\n",
        "    gap_of_x = LO_c_of_x - LT_of_Uc\n",
        "\n",
        "    delta_U_A = Ua_np - Ua_pp\n",
        "\n",
        "    n = 9\n",
        "    W = gap_of_x\n",
        "    min_cost, min_list = FindMCC(n, W, x, word_list)\n",
        "    if binomial_NB(x, word_list) == 1 and min_cost < delta_U_A:\n",
        "        return ['mod', (min_cost, min_list)]\n",
        "    else:\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5XU4vK-h2Ra"
      },
      "source": [
        "alterated_data = []\n",
        "count = 0\n",
        "for i, te in enumerate(test_data_10_nb):\n",
        "    adv_out = A(te, top_10_IG_words)\n",
        "    alterated_data.append(adv_out)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F2L4bOy2My2"
      },
      "source": [
        "def modify(mod_list, true_list):\n",
        "    nl = true_list.copy()\n",
        "    for ind, val in mod_list:\n",
        "        if val == 1:nl[ind] = val\n",
        "        else:continue      \n",
        "    return nl        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nq-HAmD2VUf2"
      },
      "source": [
        "print(alterated_data[0][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8qy1c0b0Lm-"
      },
      "source": [
        "final_altered_data = []\n",
        "mod_count = 0\n",
        "for mod_l, true_l in zip(alterated_data, test_data_10_nb):\n",
        "\n",
        "    if mod_l[0] == 'mod':\n",
        "        new_l = modify(mod_l[1][1], true_l)\n",
        "        final_altered_data.append(new_l)\n",
        "        print(new_l, true_l)\n",
        "        if new_l == true_l:\n",
        "            mod_count+=1\n",
        "\n",
        "    else:\n",
        "        final_altered_data.append(true_l)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDg6WE_sVkeI"
      },
      "source": [
        "Before adversarial modification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fzn2m6XzeHeV"
      },
      "source": [
        "pred_labels = []\n",
        "for fv in test_data_10_nb:\n",
        "    pred_labels.append(binomial_NB(fv, top_10_IG_words))\n",
        "\n",
        "true_labels_test = [0] * 241 + [1] * 48\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(true_labels_test, pred_labels)\n",
        "print(cm)\n",
        "print_spam_precision_recall(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMjLk7UbVi02"
      },
      "source": [
        "After adversarial modification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6btMeEzlhKD"
      },
      "source": [
        "pred_labels = []\n",
        "for fv in final_altered_data:\n",
        "    pred_labels.append(binomial_NB(fv, top_10_IG_words))\n",
        "\n",
        "true_labels_test = [0] * 241 + [1] * 48\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(true_labels_test, pred_labels)\n",
        "print(cm)\n",
        "print_spam_precision_recall(cm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-ETTDgie-jR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}